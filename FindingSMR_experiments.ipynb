{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CP1 Experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.naive_bayes import CategoricalNB\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.metrics import accuracy_score\n",
    "#from sklearn.metrics import precision_score\n",
    "#from sklearn.metrics import recall_score\n",
    "import time\n",
    "import re\n",
    "from pyinstrument import Profiler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('D:/KOPro/PhD/TechDelivery/SourceCode/py37/data/recordTweets10to260CP1.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A1. All Tokens (baseline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#A1. All Tokens (baseline)\n",
    "corpus = data['cleanSupText']\n",
    "corpus = corpus.fillna(value='')\n",
    "cv = CountVectorizer(min_df=2,ngram_range=(1,1),max_features=20000)\n",
    "data_cv = cv.fit_transform(corpus)\n",
    "cv_dtm = pd.DataFrame(data_cv.toarray(), columns=cv.get_feature_names())\n",
    "cv_dtm.index = corpus.index\n",
    "y = data['target']\n",
    "X = cv_dtm\n",
    "train_ratio = 0.75\n",
    "val_ratio = 0.15\n",
    "test_ratio = 0.15\n",
    "X_train, X_test_val, y_train, y_test_val = train_test_split(X, y, test_size=1-train_ratio, stratify=y, random_state=1)\n",
    "X_test, X_val, y_test, y_val = train_test_split(X_test_val, y_test_val, test_size=test_ratio/(test_ratio+val_ratio), stratify=y_test_val, random_state=1)\n",
    "#Random Forest\n",
    "rf_clf = RandomForestClassifier(n_estimators=100, random_state=0, n_jobs=-1)\n",
    "rf_clf.fit(X_train, y_train)\n",
    "rf_y_test_pred = rf_clf.predict(X_test)\n",
    "rf_y_val_pred = rf_clf.predict(X_val)\n",
    "rf_test_acc = accuracy_score(y_test, rf_y_test_pred)\n",
    "rf_val_acc = accuracy_score(y_val, rf_y_val_pred)\n",
    "time.sleep(1)\n",
    "#Gradient Boosting\n",
    "gb_clf = GradientBoostingClassifier(n_estimators=100, random_state=0)\n",
    "gb_clf.fit(X_train, y_train)\n",
    "gb_y_test_pred = gb_clf.predict(X_test)\n",
    "gb_y_val_pred = gb_clf.predict(X_val)\n",
    "gb_test_acc = accuracy_score(y_test, gb_y_test_pred)\n",
    "gb_val_acc = accuracy_score(y_val, gb_y_val_pred)\n",
    "time.sleep(1)\n",
    "#AdaBoost\n",
    "ab_clf = AdaBoostClassifier(n_estimators=50, random_state=0)\n",
    "ab_clf.fit(X_train, y_train)\n",
    "ab_y_test_pred = ab_clf.predict(X_test)\n",
    "ab_y_val_pred = ab_clf.predict(X_val)\n",
    "ab_test_acc = accuracy_score(y_test, ab_y_test_pred)\n",
    "ab_val_acc = accuracy_score(y_val, ab_y_val_pred)\n",
    "time.sleep(1)\n",
    "#Support Vector Machine\n",
    "svm_clf = SVC(kernel='linear')\n",
    "svm_clf.fit(X_train, y_train)\n",
    "svm_y_test_pred = svm_clf.predict(X_test)\n",
    "svm_y_val_pred = svm_clf.predict(X_val)\n",
    "svm_test_acc = accuracy_score(y_test, svm_y_test_pred)\n",
    "svm_val_acc = accuracy_score(y_val, svm_y_val_pred)\n",
    "time.sleep(1)\n",
    "#Gaussian Naive Bayes\n",
    "gnb_clf = GaussianNB()\n",
    "gnb_clf.fit(X_train, y_train)\n",
    "gnb_y_test_pred = gnb_clf.predict(X_test)\n",
    "gnb_y_val_pred = gnb_clf.predict(X_val)\n",
    "gnb_test_acc = accuracy_score(y_test, gnb_y_test_pred)\n",
    "gnb_val_acc = accuracy_score(y_val, gnb_y_val_pred)\n",
    "time.sleep(1)\n",
    "#Latent Dirichlet Allocation\n",
    "lda_clf = LinearDiscriminantAnalysis()\n",
    "lda_clf.fit(X_train, y_train)\n",
    "lda_y_test_pred = lda_clf.predict(X_test)\n",
    "lda_y_val_pred = lda_clf.predict(X_val)\n",
    "lda_test_acc = accuracy_score(y_test, lda_y_test_pred)\n",
    "lda_val_acc = accuracy_score(y_val, lda_y_val_pred)\n",
    "time.sleep(1)\n",
    "print ('Result A1. All Tokens (baseline) ')\n",
    "print (rf_test_acc,rf_val_acc,gb_test_acc,gb_val_acc,ab_test_acc,ab_val_acc,svm_test_acc,svm_val_acc,gnb_test_acc,gnb_val_acc,lda_test_acc,lda_val_acc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A2. Nouns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#A2. Nouns\n",
    "corpus = data['supNouns']\n",
    "corpus = corpus.fillna(value='')\n",
    "cv = CountVectorizer(min_df=2,ngram_range=(1,1),max_features=20000)\n",
    "data_cv = cv.fit_transform(corpus)\n",
    "cv_dtm = pd.DataFrame(data_cv.toarray(), columns=cv.get_feature_names())\n",
    "cv_dtm.index = corpus.index\n",
    "y = data['target']\n",
    "X = cv_dtm\n",
    "train_ratio = 0.75\n",
    "val_ratio = 0.15\n",
    "test_ratio = 0.15\n",
    "X_train, X_test_val, y_train, y_test_val = train_test_split(X, y, test_size=1-train_ratio, stratify=y, random_state=1)\n",
    "X_test, X_val, y_test, y_val = train_test_split(X_test_val, y_test_val, test_size=test_ratio/(test_ratio+val_ratio), stratify=y_test_val, random_state=1)\n",
    "#Random Forest\n",
    "rf_clf = RandomForestClassifier(n_estimators=100, random_state=0, n_jobs=-1)\n",
    "rf_clf.fit(X_train, y_train)\n",
    "rf_y_test_pred = rf_clf.predict(X_test)\n",
    "rf_y_val_pred = rf_clf.predict(X_val)\n",
    "rf_test_acc = accuracy_score(y_test, rf_y_test_pred)\n",
    "rf_val_acc = accuracy_score(y_val, rf_y_val_pred)\n",
    "time.sleep(1)\n",
    "#Gradient Boosting\n",
    "gb_clf = GradientBoostingClassifier(n_estimators=100, random_state=0)\n",
    "gb_clf.fit(X_train, y_train)\n",
    "gb_y_test_pred = gb_clf.predict(X_test)\n",
    "gb_y_val_pred = gb_clf.predict(X_val)\n",
    "gb_test_acc = accuracy_score(y_test, gb_y_test_pred)\n",
    "gb_val_acc = accuracy_score(y_val, gb_y_val_pred)\n",
    "time.sleep(1)\n",
    "#AdaBoost\n",
    "ab_clf = AdaBoostClassifier(n_estimators=50, random_state=0)\n",
    "ab_clf.fit(X_train, y_train)\n",
    "ab_y_test_pred = ab_clf.predict(X_test)\n",
    "ab_y_val_pred = ab_clf.predict(X_val)\n",
    "ab_test_acc = accuracy_score(y_test, ab_y_test_pred)\n",
    "ab_val_acc = accuracy_score(y_val, ab_y_val_pred)\n",
    "time.sleep(1)\n",
    "#Support Vector Machine\n",
    "svm_clf = SVC(kernel='linear')\n",
    "svm_clf.fit(X_train, y_train)\n",
    "svm_y_test_pred = svm_clf.predict(X_test)\n",
    "svm_y_val_pred = svm_clf.predict(X_val)\n",
    "svm_test_acc = accuracy_score(y_test, svm_y_test_pred)\n",
    "svm_val_acc = accuracy_score(y_val, svm_y_val_pred)\n",
    "time.sleep(1)\n",
    "#Gaussian Naive Bayes\n",
    "gnb_clf = GaussianNB()\n",
    "gnb_clf.fit(X_train, y_train)\n",
    "gnb_y_test_pred = gnb_clf.predict(X_test)\n",
    "gnb_y_val_pred = gnb_clf.predict(X_val)\n",
    "gnb_test_acc = accuracy_score(y_test, gnb_y_test_pred)\n",
    "gnb_val_acc = accuracy_score(y_val, gnb_y_val_pred)\n",
    "time.sleep(1)\n",
    "#Latent Dirichlet Allocation\n",
    "lda_clf = LinearDiscriminantAnalysis()\n",
    "lda_clf.fit(X_train, y_train)\n",
    "lda_y_test_pred = lda_clf.predict(X_test)\n",
    "lda_y_val_pred = lda_clf.predict(X_val)\n",
    "lda_test_acc = accuracy_score(y_test, lda_y_test_pred)\n",
    "lda_val_acc = accuracy_score(y_val, lda_y_val_pred)\n",
    "time.sleep(1)\n",
    "print ('Result A2: Nouns. ')\n",
    "print (rf_test_acc,rf_val_acc,gb_test_acc,gb_val_acc,ab_test_acc,ab_val_acc,svm_test_acc,svm_val_acc,gnb_test_acc,gnb_val_acc,lda_test_acc,lda_val_acc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A3. Verbs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#A3. Verbs\n",
    "corpus = data['supVerbs']\n",
    "corpus = corpus.fillna(value='')\n",
    "cv = CountVectorizer(min_df=2,ngram_range=(1,1),max_features=20000)\n",
    "data_cv = cv.fit_transform(corpus)\n",
    "cv_dtm = pd.DataFrame(data_cv.toarray(), columns=cv.get_feature_names())\n",
    "cv_dtm.index = corpus.index\n",
    "y = data['target']\n",
    "X = cv_dtm\n",
    "train_ratio = 0.75\n",
    "val_ratio = 0.15\n",
    "test_ratio = 0.15\n",
    "X_train, X_test_val, y_train, y_test_val = train_test_split(X, y, test_size=1-train_ratio, stratify=y, random_state=1)\n",
    "X_test, X_val, y_test, y_val = train_test_split(X_test_val, y_test_val, test_size=test_ratio/(test_ratio+val_ratio), stratify=y_test_val, random_state=1)\n",
    "#Random Forest\n",
    "rf_clf = RandomForestClassifier(n_estimators=100, random_state=0, n_jobs=-1)\n",
    "rf_clf.fit(X_train, y_train)\n",
    "rf_y_test_pred = rf_clf.predict(X_test)\n",
    "rf_y_val_pred = rf_clf.predict(X_val)\n",
    "rf_test_acc = accuracy_score(y_test, rf_y_test_pred)\n",
    "rf_val_acc = accuracy_score(y_val, rf_y_val_pred)\n",
    "time.sleep(1)\n",
    "#Gradient Boosting\n",
    "gb_clf = GradientBoostingClassifier(n_estimators=100, random_state=0)\n",
    "gb_clf.fit(X_train, y_train)\n",
    "gb_y_test_pred = gb_clf.predict(X_test)\n",
    "gb_y_val_pred = gb_clf.predict(X_val)\n",
    "gb_test_acc = accuracy_score(y_test, gb_y_test_pred)\n",
    "gb_val_acc = accuracy_score(y_val, gb_y_val_pred)\n",
    "time.sleep(1)\n",
    "#AdaBoost\n",
    "ab_clf = AdaBoostClassifier(n_estimators=50, random_state=0)\n",
    "ab_clf.fit(X_train, y_train)\n",
    "ab_y_test_pred = ab_clf.predict(X_test)\n",
    "ab_y_val_pred = ab_clf.predict(X_val)\n",
    "ab_test_acc = accuracy_score(y_test, ab_y_test_pred)\n",
    "ab_val_acc = accuracy_score(y_val, ab_y_val_pred)\n",
    "time.sleep(1)\n",
    "#Support Vector Machine\n",
    "svm_clf = SVC(kernel='linear')\n",
    "svm_clf.fit(X_train, y_train)\n",
    "svm_y_test_pred = svm_clf.predict(X_test)\n",
    "svm_y_val_pred = svm_clf.predict(X_val)\n",
    "svm_test_acc = accuracy_score(y_test, svm_y_test_pred)\n",
    "svm_val_acc = accuracy_score(y_val, svm_y_val_pred)\n",
    "time.sleep(1)\n",
    "#Gaussian Naive Bayes\n",
    "gnb_clf = GaussianNB()\n",
    "gnb_clf.fit(X_train, y_train)\n",
    "gnb_y_test_pred = gnb_clf.predict(X_test)\n",
    "gnb_y_val_pred = gnb_clf.predict(X_val)\n",
    "gnb_test_acc = accuracy_score(y_test, gnb_y_test_pred)\n",
    "gnb_val_acc = accuracy_score(y_val, gnb_y_val_pred)\n",
    "time.sleep(1)\n",
    "#Latent Dirichlet Allocation\n",
    "lda_clf = LinearDiscriminantAnalysis()\n",
    "lda_clf.fit(X_train, y_train)\n",
    "lda_y_test_pred = lda_clf.predict(X_test)\n",
    "lda_y_val_pred = lda_clf.predict(X_val)\n",
    "lda_test_acc = accuracy_score(y_test, lda_y_test_pred)\n",
    "lda_val_acc = accuracy_score(y_val, lda_y_val_pred)\n",
    "time.sleep(1)\n",
    "print ('Result A3: Verbs ')\n",
    "print (rf_test_acc,rf_val_acc,gb_test_acc,gb_val_acc,ab_test_acc,ab_val_acc,svm_test_acc,svm_val_acc,gnb_test_acc,gnb_val_acc,lda_test_acc,lda_val_acc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A4. Named Entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#A4. Named Entities\n",
    "corpus = data['supNER']\n",
    "corpus = corpus.fillna(value='')\n",
    "cv = CountVectorizer(min_df=2,ngram_range=(1,1),max_features=20000)\n",
    "data_cv = cv.fit_transform(corpus)\n",
    "cv_dtm = pd.DataFrame(data_cv.toarray(), columns=cv.get_feature_names())\n",
    "cv_dtm.index = corpus.index\n",
    "y = data['target']\n",
    "X = cv_dtm\n",
    "train_ratio = 0.75\n",
    "val_ratio = 0.15\n",
    "test_ratio = 0.15\n",
    "X_train, X_test_val, y_train, y_test_val = train_test_split(X, y, test_size=1-train_ratio, stratify=y, random_state=1)\n",
    "X_test, X_val, y_test, y_val = train_test_split(X_test_val, y_test_val, test_size=test_ratio/(test_ratio+val_ratio), stratify=y_test_val, random_state=1)\n",
    "#Random Forest\n",
    "rf_clf = RandomForestClassifier(n_estimators=100, random_state=0, n_jobs=-1)\n",
    "rf_clf.fit(X_train, y_train)\n",
    "rf_y_test_pred = rf_clf.predict(X_test)\n",
    "rf_y_val_pred = rf_clf.predict(X_val)\n",
    "rf_test_acc = accuracy_score(y_test, rf_y_test_pred)\n",
    "rf_val_acc = accuracy_score(y_val, rf_y_val_pred)\n",
    "time.sleep(1)\n",
    "#Gradient Boosting\n",
    "gb_clf = GradientBoostingClassifier(n_estimators=100, random_state=0)\n",
    "gb_clf.fit(X_train, y_train)\n",
    "gb_y_test_pred = gb_clf.predict(X_test)\n",
    "gb_y_val_pred = gb_clf.predict(X_val)\n",
    "gb_test_acc = accuracy_score(y_test, gb_y_test_pred)\n",
    "gb_val_acc = accuracy_score(y_val, gb_y_val_pred)\n",
    "time.sleep(1)\n",
    "#AdaBoost\n",
    "ab_clf = AdaBoostClassifier(n_estimators=50, random_state=0)\n",
    "ab_clf.fit(X_train, y_train)\n",
    "ab_y_test_pred = ab_clf.predict(X_test)\n",
    "ab_y_val_pred = ab_clf.predict(X_val)\n",
    "ab_test_acc = accuracy_score(y_test, ab_y_test_pred)\n",
    "ab_val_acc = accuracy_score(y_val, ab_y_val_pred)\n",
    "time.sleep(1)\n",
    "#Support Vector Machine\n",
    "svm_clf = SVC(kernel='linear')\n",
    "svm_clf.fit(X_train, y_train)\n",
    "svm_y_test_pred = svm_clf.predict(X_test)\n",
    "svm_y_val_pred = svm_clf.predict(X_val)\n",
    "svm_test_acc = accuracy_score(y_test, svm_y_test_pred)\n",
    "svm_val_acc = accuracy_score(y_val, svm_y_val_pred)\n",
    "time.sleep(1)\n",
    "#Gaussian Naive Bayes\n",
    "gnb_clf = GaussianNB()\n",
    "gnb_clf.fit(X_train, y_train)\n",
    "gnb_y_test_pred = gnb_clf.predict(X_test)\n",
    "gnb_y_val_pred = gnb_clf.predict(X_val)\n",
    "gnb_test_acc = accuracy_score(y_test, gnb_y_test_pred)\n",
    "gnb_val_acc = accuracy_score(y_val, gnb_y_val_pred)\n",
    "time.sleep(1)\n",
    "#Latent Dirichlet Allocation\n",
    "lda_clf = LinearDiscriminantAnalysis()\n",
    "lda_clf.fit(X_train, y_train)\n",
    "lda_y_test_pred = lda_clf.predict(X_test)\n",
    "lda_y_val_pred = lda_clf.predict(X_val)\n",
    "lda_test_acc = accuracy_score(y_test, lda_y_test_pred)\n",
    "lda_val_acc = accuracy_score(y_val, lda_y_val_pred)\n",
    "time.sleep(1)\n",
    "print ('Result A4: Named Entities ')\n",
    "print (rf_test_acc,rf_val_acc,gb_test_acc,gb_val_acc,ab_test_acc,ab_val_acc,svm_test_acc,svm_val_acc,gnb_test_acc,gnb_val_acc,lda_test_acc,lda_val_acc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A5. Hashtags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#A5. Hashtags\n",
    "corpus = data['supHashtags']\n",
    "corpus = corpus.fillna(value='')\n",
    "cv = CountVectorizer(min_df=2,ngram_range=(1,1),max_features=20000)\n",
    "data_cv = cv.fit_transform(corpus)\n",
    "cv_dtm = pd.DataFrame(data_cv.toarray(), columns=cv.get_feature_names())\n",
    "cv_dtm.index = corpus.index\n",
    "y = data['target']\n",
    "X = cv_dtm\n",
    "train_ratio = 0.75\n",
    "val_ratio = 0.15\n",
    "test_ratio = 0.15\n",
    "X_train, X_test_val, y_train, y_test_val = train_test_split(X, y, test_size=1-train_ratio, stratify=y, random_state=1)\n",
    "X_test, X_val, y_test, y_val = train_test_split(X_test_val, y_test_val, test_size=test_ratio/(test_ratio+val_ratio), stratify=y_test_val, random_state=1)\n",
    "#Random Forest\n",
    "rf_clf = RandomForestClassifier(n_estimators=100, random_state=0, n_jobs=-1)\n",
    "rf_clf.fit(X_train, y_train)\n",
    "rf_y_test_pred = rf_clf.predict(X_test)\n",
    "rf_y_val_pred = rf_clf.predict(X_val)\n",
    "rf_test_acc = accuracy_score(y_test, rf_y_test_pred)\n",
    "rf_val_acc = accuracy_score(y_val, rf_y_val_pred)\n",
    "time.sleep(1)\n",
    "#Gradient Boosting\n",
    "gb_clf = GradientBoostingClassifier(n_estimators=100, random_state=0)\n",
    "gb_clf.fit(X_train, y_train)\n",
    "gb_y_test_pred = gb_clf.predict(X_test)\n",
    "gb_y_val_pred = gb_clf.predict(X_val)\n",
    "gb_test_acc = accuracy_score(y_test, gb_y_test_pred)\n",
    "gb_val_acc = accuracy_score(y_val, gb_y_val_pred)\n",
    "time.sleep(1)\n",
    "#AdaBoost\n",
    "ab_clf = AdaBoostClassifier(n_estimators=50, random_state=0)\n",
    "ab_clf.fit(X_train, y_train)\n",
    "ab_y_test_pred = ab_clf.predict(X_test)\n",
    "ab_y_val_pred = ab_clf.predict(X_val)\n",
    "ab_test_acc = accuracy_score(y_test, ab_y_test_pred)\n",
    "ab_val_acc = accuracy_score(y_val, ab_y_val_pred)\n",
    "time.sleep(1)\n",
    "#Support Vector Machine\n",
    "svm_clf = SVC(kernel='linear')\n",
    "svm_clf.fit(X_train, y_train)\n",
    "svm_y_test_pred = svm_clf.predict(X_test)\n",
    "svm_y_val_pred = svm_clf.predict(X_val)\n",
    "svm_test_acc = accuracy_score(y_test, svm_y_test_pred)\n",
    "svm_val_acc = accuracy_score(y_val, svm_y_val_pred)\n",
    "time.sleep(1)\n",
    "#Gaussian Naive Bayes\n",
    "gnb_clf = GaussianNB()\n",
    "gnb_clf.fit(X_train, y_train)\n",
    "gnb_y_test_pred = gnb_clf.predict(X_test)\n",
    "gnb_y_val_pred = gnb_clf.predict(X_val)\n",
    "gnb_test_acc = accuracy_score(y_test, gnb_y_test_pred)\n",
    "gnb_val_acc = accuracy_score(y_val, gnb_y_val_pred)\n",
    "time.sleep(1)\n",
    "#Latent Dirichlet Allocation\n",
    "lda_clf = LinearDiscriminantAnalysis()\n",
    "lda_clf.fit(X_train, y_train)\n",
    "lda_y_test_pred = lda_clf.predict(X_test)\n",
    "lda_y_val_pred = lda_clf.predict(X_val)\n",
    "lda_test_acc = accuracy_score(y_test, lda_y_test_pred)\n",
    "lda_val_acc = accuracy_score(y_val, lda_y_val_pred)\n",
    "time.sleep(1)\n",
    "print ('Result A5: Hashtags ')\n",
    "print (rf_test_acc,rf_val_acc,gb_test_acc,gb_val_acc,ab_test_acc,ab_val_acc,svm_test_acc,svm_val_acc,gnb_test_acc,gnb_val_acc,lda_test_acc,lda_val_acc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A6. Mentions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#A6. Mentions\n",
    "corpus = data['supMentions']\n",
    "corpus = corpus.fillna(value='')\n",
    "cv = CountVectorizer(min_df=2,ngram_range=(1,1),max_features=20000)\n",
    "data_cv = cv.fit_transform(corpus)\n",
    "cv_dtm = pd.DataFrame(data_cv.toarray(), columns=cv.get_feature_names())\n",
    "cv_dtm.index = corpus.index\n",
    "y = data['target']\n",
    "X = cv_dtm\n",
    "train_ratio = 0.75\n",
    "val_ratio = 0.15\n",
    "test_ratio = 0.15\n",
    "X_train, X_test_val, y_train, y_test_val = train_test_split(X, y, test_size=1-train_ratio, stratify=y, random_state=1)\n",
    "X_test, X_val, y_test, y_val = train_test_split(X_test_val, y_test_val, test_size=test_ratio/(test_ratio+val_ratio), stratify=y_test_val, random_state=1)\n",
    "#Random Forest\n",
    "rf_clf = RandomForestClassifier(n_estimators=100, random_state=0, n_jobs=-1)\n",
    "rf_clf.fit(X_train, y_train)\n",
    "rf_y_test_pred = rf_clf.predict(X_test)\n",
    "rf_y_val_pred = rf_clf.predict(X_val)\n",
    "rf_test_acc = accuracy_score(y_test, rf_y_test_pred)\n",
    "rf_val_acc = accuracy_score(y_val, rf_y_val_pred)\n",
    "time.sleep(1)\n",
    "#Gradient Boosting\n",
    "gb_clf = GradientBoostingClassifier(n_estimators=100, random_state=0)\n",
    "gb_clf.fit(X_train, y_train)\n",
    "gb_y_test_pred = gb_clf.predict(X_test)\n",
    "gb_y_val_pred = gb_clf.predict(X_val)\n",
    "gb_test_acc = accuracy_score(y_test, gb_y_test_pred)\n",
    "gb_val_acc = accuracy_score(y_val, gb_y_val_pred)\n",
    "time.sleep(1)\n",
    "#AdaBoost\n",
    "ab_clf = AdaBoostClassifier(n_estimators=50, random_state=0)\n",
    "ab_clf.fit(X_train, y_train)\n",
    "ab_y_test_pred = ab_clf.predict(X_test)\n",
    "ab_y_val_pred = ab_clf.predict(X_val)\n",
    "ab_test_acc = accuracy_score(y_test, ab_y_test_pred)\n",
    "ab_val_acc = accuracy_score(y_val, ab_y_val_pred)\n",
    "time.sleep(1)\n",
    "#Support Vector Machine\n",
    "svm_clf = SVC(kernel='linear')\n",
    "svm_clf.fit(X_train, y_train)\n",
    "svm_y_test_pred = svm_clf.predict(X_test)\n",
    "svm_y_val_pred = svm_clf.predict(X_val)\n",
    "svm_test_acc = accuracy_score(y_test, svm_y_test_pred)\n",
    "svm_val_acc = accuracy_score(y_val, svm_y_val_pred)\n",
    "time.sleep(1)\n",
    "#Gaussian Naive Bayes\n",
    "gnb_clf = GaussianNB()\n",
    "gnb_clf.fit(X_train, y_train)\n",
    "gnb_y_test_pred = gnb_clf.predict(X_test)\n",
    "gnb_y_val_pred = gnb_clf.predict(X_val)\n",
    "gnb_test_acc = accuracy_score(y_test, gnb_y_test_pred)\n",
    "gnb_val_acc = accuracy_score(y_val, gnb_y_val_pred)\n",
    "time.sleep(1)\n",
    "#Latent Dirichlet Allocation\n",
    "lda_clf = LinearDiscriminantAnalysis()\n",
    "lda_clf.fit(X_train, y_train)\n",
    "lda_y_test_pred = lda_clf.predict(X_test)\n",
    "lda_y_val_pred = lda_clf.predict(X_val)\n",
    "lda_test_acc = accuracy_score(y_test, lda_y_test_pred)\n",
    "lda_val_acc = accuracy_score(y_val, lda_y_val_pred)\n",
    "time.sleep(1)\n",
    "print ('Result A6: Mentions ')\n",
    "print (rf_test_acc,rf_val_acc,gb_test_acc,gb_val_acc,ab_test_acc,ab_val_acc,svm_test_acc,svm_val_acc,gnb_test_acc,gnb_val_acc,lda_test_acc,lda_val_acc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A7. Nouns+Verbs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#A7. Nouns+Verbs\n",
    "corpus = data['supNouns'] + data['supVerbs']\n",
    "corpus = corpus.fillna(value='')\n",
    "cv = CountVectorizer(min_df=2,ngram_range=(1,1),max_features=20000)\n",
    "data_cv = cv.fit_transform(corpus)\n",
    "cv_dtm = pd.DataFrame(data_cv.toarray(), columns=cv.get_feature_names())\n",
    "cv_dtm.index = corpus.index\n",
    "y = data['target']\n",
    "X = cv_dtm\n",
    "train_ratio = 0.75\n",
    "val_ratio = 0.15\n",
    "test_ratio = 0.15\n",
    "X_train, X_test_val, y_train, y_test_val = train_test_split(X, y, test_size=1-train_ratio, stratify=y, random_state=1)\n",
    "X_test, X_val, y_test, y_val = train_test_split(X_test_val, y_test_val, test_size=test_ratio/(test_ratio+val_ratio), stratify=y_test_val, random_state=1)\n",
    "#Random Forest\n",
    "rf_clf = RandomForestClassifier(n_estimators=100, random_state=0, n_jobs=-1)\n",
    "rf_clf.fit(X_train, y_train)\n",
    "rf_y_test_pred = rf_clf.predict(X_test)\n",
    "rf_y_val_pred = rf_clf.predict(X_val)\n",
    "rf_test_acc = accuracy_score(y_test, rf_y_test_pred)\n",
    "rf_val_acc = accuracy_score(y_val, rf_y_val_pred)\n",
    "time.sleep(1)\n",
    "#Gradient Boosting\n",
    "gb_clf = GradientBoostingClassifier(n_estimators=100, random_state=0)\n",
    "gb_clf.fit(X_train, y_train)\n",
    "gb_y_test_pred = gb_clf.predict(X_test)\n",
    "gb_y_val_pred = gb_clf.predict(X_val)\n",
    "gb_test_acc = accuracy_score(y_test, gb_y_test_pred)\n",
    "gb_val_acc = accuracy_score(y_val, gb_y_val_pred)\n",
    "time.sleep(1)\n",
    "#AdaBoost\n",
    "ab_clf = AdaBoostClassifier(n_estimators=50, random_state=0)\n",
    "ab_clf.fit(X_train, y_train)\n",
    "ab_y_test_pred = ab_clf.predict(X_test)\n",
    "ab_y_val_pred = ab_clf.predict(X_val)\n",
    "ab_test_acc = accuracy_score(y_test, ab_y_test_pred)\n",
    "ab_val_acc = accuracy_score(y_val, ab_y_val_pred)\n",
    "time.sleep(1)\n",
    "#Support Vector Machine\n",
    "svm_clf = SVC(kernel='linear')\n",
    "svm_clf.fit(X_train, y_train)\n",
    "svm_y_test_pred = svm_clf.predict(X_test)\n",
    "svm_y_val_pred = svm_clf.predict(X_val)\n",
    "svm_test_acc = accuracy_score(y_test, svm_y_test_pred)\n",
    "svm_val_acc = accuracy_score(y_val, svm_y_val_pred)\n",
    "time.sleep(1)\n",
    "#Gaussian Naive Bayes\n",
    "gnb_clf = GaussianNB()\n",
    "gnb_clf.fit(X_train, y_train)\n",
    "gnb_y_test_pred = gnb_clf.predict(X_test)\n",
    "gnb_y_val_pred = gnb_clf.predict(X_val)\n",
    "gnb_test_acc = accuracy_score(y_test, gnb_y_test_pred)\n",
    "gnb_val_acc = accuracy_score(y_val, gnb_y_val_pred)\n",
    "time.sleep(1)\n",
    "#Latent Dirichlet Allocation\n",
    "lda_clf = LinearDiscriminantAnalysis()\n",
    "lda_clf.fit(X_train, y_train)\n",
    "lda_y_test_pred = lda_clf.predict(X_test)\n",
    "lda_y_val_pred = lda_clf.predict(X_val)\n",
    "lda_test_acc = accuracy_score(y_test, lda_y_test_pred)\n",
    "lda_val_acc = accuracy_score(y_val, lda_y_val_pred)\n",
    "time.sleep(1)\n",
    "print ('Result A7: Nouns+Verbs ')\n",
    "print (rf_test_acc,rf_val_acc,gb_test_acc,gb_val_acc,ab_test_acc,ab_val_acc,svm_test_acc,svm_val_acc,gnb_test_acc,gnb_val_acc,lda_test_acc,lda_val_acc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A8. Mentions+Nouns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#A8. Mentions+Nouns\n",
    "corpus = data['supMentions'] + data['supNouns']\n",
    "corpus = corpus.fillna(value='')\n",
    "cv = CountVectorizer(min_df=2,ngram_range=(1,1),max_features=20000)\n",
    "data_cv = cv.fit_transform(corpus)\n",
    "cv_dtm = pd.DataFrame(data_cv.toarray(), columns=cv.get_feature_names())\n",
    "cv_dtm.index = corpus.index\n",
    "y = data['target']\n",
    "X = cv_dtm\n",
    "train_ratio = 0.75\n",
    "val_ratio = 0.15\n",
    "test_ratio = 0.15\n",
    "X_train, X_test_val, y_train, y_test_val = train_test_split(X, y, test_size=1-train_ratio, stratify=y, random_state=1)\n",
    "X_test, X_val, y_test, y_val = train_test_split(X_test_val, y_test_val, test_size=test_ratio/(test_ratio+val_ratio), stratify=y_test_val, random_state=1)\n",
    "#Random Forest\n",
    "rf_clf = RandomForestClassifier(n_estimators=100, random_state=0, n_jobs=-1)\n",
    "rf_clf.fit(X_train, y_train)\n",
    "rf_y_test_pred = rf_clf.predict(X_test)\n",
    "rf_y_val_pred = rf_clf.predict(X_val)\n",
    "rf_test_acc = accuracy_score(y_test, rf_y_test_pred)\n",
    "rf_val_acc = accuracy_score(y_val, rf_y_val_pred)\n",
    "time.sleep(1)\n",
    "#Gradient Boosting\n",
    "gb_clf = GradientBoostingClassifier(n_estimators=100, random_state=0)\n",
    "gb_clf.fit(X_train, y_train)\n",
    "gb_y_test_pred = gb_clf.predict(X_test)\n",
    "gb_y_val_pred = gb_clf.predict(X_val)\n",
    "gb_test_acc = accuracy_score(y_test, gb_y_test_pred)\n",
    "gb_val_acc = accuracy_score(y_val, gb_y_val_pred)\n",
    "time.sleep(1)\n",
    "#AdaBoost\n",
    "ab_clf = AdaBoostClassifier(n_estimators=50, random_state=0)\n",
    "ab_clf.fit(X_train, y_train)\n",
    "ab_y_test_pred = ab_clf.predict(X_test)\n",
    "ab_y_val_pred = ab_clf.predict(X_val)\n",
    "ab_test_acc = accuracy_score(y_test, ab_y_test_pred)\n",
    "ab_val_acc = accuracy_score(y_val, ab_y_val_pred)\n",
    "time.sleep(1)\n",
    "#Support Vector Machine\n",
    "svm_clf = SVC(kernel='linear')\n",
    "svm_clf.fit(X_train, y_train)\n",
    "svm_y_test_pred = svm_clf.predict(X_test)\n",
    "svm_y_val_pred = svm_clf.predict(X_val)\n",
    "svm_test_acc = accuracy_score(y_test, svm_y_test_pred)\n",
    "svm_val_acc = accuracy_score(y_val, svm_y_val_pred)\n",
    "time.sleep(1)\n",
    "#Gaussian Naive Bayes\n",
    "gnb_clf = GaussianNB()\n",
    "gnb_clf.fit(X_train, y_train)\n",
    "gnb_y_test_pred = gnb_clf.predict(X_test)\n",
    "gnb_y_val_pred = gnb_clf.predict(X_val)\n",
    "gnb_test_acc = accuracy_score(y_test, gnb_y_test_pred)\n",
    "gnb_val_acc = accuracy_score(y_val, gnb_y_val_pred)\n",
    "time.sleep(1)\n",
    "#Latent Dirichlet Allocation\n",
    "lda_clf = LinearDiscriminantAnalysis()\n",
    "lda_clf.fit(X_train, y_train)\n",
    "lda_y_test_pred = lda_clf.predict(X_test)\n",
    "lda_y_val_pred = lda_clf.predict(X_val)\n",
    "lda_test_acc = accuracy_score(y_test, lda_y_test_pred)\n",
    "lda_val_acc = accuracy_score(y_val, lda_y_val_pred)\n",
    "time.sleep(1)\n",
    "print ('Result A8: Mentions+Nouns ')\n",
    "print (rf_test_acc,rf_val_acc,gb_test_acc,gb_val_acc,ab_test_acc,ab_val_acc,svm_test_acc,svm_val_acc,gnb_test_acc,gnb_val_acc,lda_test_acc,lda_val_acc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A9. Mentions+NamedEntities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#A9. Mentions+NamedEntities\n",
    "corpus = data['supMentions'] + data['supNER']\n",
    "corpus = corpus.fillna(value='')\n",
    "cv = CountVectorizer(min_df=2,ngram_range=(1,1),max_features=20000)\n",
    "data_cv = cv.fit_transform(corpus)\n",
    "cv_dtm = pd.DataFrame(data_cv.toarray(), columns=cv.get_feature_names())\n",
    "cv_dtm.index = corpus.index\n",
    "y = data['target']\n",
    "X = cv_dtm\n",
    "train_ratio = 0.75\n",
    "val_ratio = 0.15\n",
    "test_ratio = 0.15\n",
    "X_train, X_test_val, y_train, y_test_val = train_test_split(X, y, test_size=1-train_ratio, stratify=y, random_state=1)\n",
    "X_test, X_val, y_test, y_val = train_test_split(X_test_val, y_test_val, test_size=test_ratio/(test_ratio+val_ratio), stratify=y_test_val, random_state=1)\n",
    "#Random Forest\n",
    "rf_clf = RandomForestClassifier(n_estimators=100, random_state=0, n_jobs=-1)\n",
    "rf_clf.fit(X_train, y_train)\n",
    "rf_y_test_pred = rf_clf.predict(X_test)\n",
    "rf_y_val_pred = rf_clf.predict(X_val)\n",
    "rf_test_acc = accuracy_score(y_test, rf_y_test_pred)\n",
    "rf_val_acc = accuracy_score(y_val, rf_y_val_pred)\n",
    "time.sleep(1)\n",
    "#Gradient Boosting\n",
    "gb_clf = GradientBoostingClassifier(n_estimators=100, random_state=0)\n",
    "gb_clf.fit(X_train, y_train)\n",
    "gb_y_test_pred = gb_clf.predict(X_test)\n",
    "gb_y_val_pred = gb_clf.predict(X_val)\n",
    "gb_test_acc = accuracy_score(y_test, gb_y_test_pred)\n",
    "gb_val_acc = accuracy_score(y_val, gb_y_val_pred)\n",
    "time.sleep(1)\n",
    "#AdaBoost\n",
    "ab_clf = AdaBoostClassifier(n_estimators=50, random_state=0)\n",
    "ab_clf.fit(X_train, y_train)\n",
    "ab_y_test_pred = ab_clf.predict(X_test)\n",
    "ab_y_val_pred = ab_clf.predict(X_val)\n",
    "ab_test_acc = accuracy_score(y_test, ab_y_test_pred)\n",
    "ab_val_acc = accuracy_score(y_val, ab_y_val_pred)\n",
    "time.sleep(1)\n",
    "#Support Vector Machine\n",
    "svm_clf = SVC(kernel='linear')\n",
    "svm_clf.fit(X_train, y_train)\n",
    "svm_y_test_pred = svm_clf.predict(X_test)\n",
    "svm_y_val_pred = svm_clf.predict(X_val)\n",
    "svm_test_acc = accuracy_score(y_test, svm_y_test_pred)\n",
    "svm_val_acc = accuracy_score(y_val, svm_y_val_pred)\n",
    "time.sleep(1)\n",
    "#Gaussian Naive Bayes\n",
    "gnb_clf = GaussianNB()\n",
    "gnb_clf.fit(X_train, y_train)\n",
    "gnb_y_test_pred = gnb_clf.predict(X_test)\n",
    "gnb_y_val_pred = gnb_clf.predict(X_val)\n",
    "gnb_test_acc = accuracy_score(y_test, gnb_y_test_pred)\n",
    "gnb_val_acc = accuracy_score(y_val, gnb_y_val_pred)\n",
    "time.sleep(1)\n",
    "#Latent Dirichlet Allocation\n",
    "lda_clf = LinearDiscriminantAnalysis()\n",
    "lda_clf.fit(X_train, y_train)\n",
    "lda_y_test_pred = lda_clf.predict(X_test)\n",
    "lda_y_val_pred = lda_clf.predict(X_val)\n",
    "lda_test_acc = accuracy_score(y_test, lda_y_test_pred)\n",
    "lda_val_acc = accuracy_score(y_val, lda_y_val_pred)\n",
    "time.sleep(1)\n",
    "print ('Result A9: Mentions+NamedEntities ')\n",
    "print (rf_test_acc,rf_val_acc,gb_test_acc,gb_val_acc,ab_test_acc,ab_val_acc,svm_test_acc,svm_val_acc,gnb_test_acc,gnb_val_acc,lda_test_acc,lda_val_acc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B1. 1-gram + 2-gram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result B1. 1-gram + 2-gram \n",
      "0.8348623853211009 0.8272727272727273 0.8532110091743119 0.8181818181818182 0.8440366972477065 0.8272727272727273\n"
     ]
    }
   ],
   "source": [
    "#B1. 1-gram + 2-gram\n",
    "corpus = data['supMentions'] + data['supNouns']\n",
    "corpus = corpus.fillna(value='')\n",
    "cv = CountVectorizer(min_df=2,ngram_range=(1,2),max_features=20000)\n",
    "data_cv = cv.fit_transform(corpus)\n",
    "cv_dtm = pd.DataFrame(data_cv.toarray(), columns=cv.get_feature_names())\n",
    "cv_dtm.index = corpus.index\n",
    "y = data['target']\n",
    "X = cv_dtm\n",
    "train_ratio = 0.75\n",
    "val_ratio = 0.15\n",
    "test_ratio = 0.15\n",
    "X_train, X_test_val, y_train, y_test_val = train_test_split(X, y, test_size=1-train_ratio, stratify=y, random_state=1)\n",
    "X_test, X_val, y_test, y_val = train_test_split(X_test_val, y_test_val, test_size=test_ratio/(test_ratio+val_ratio), stratify=y_test_val, random_state=1)\n",
    "#Random Forest\n",
    "rf_clf = RandomForestClassifier(n_estimators=100, random_state=0, n_jobs=-1)\n",
    "rf_clf.fit(X_train, y_train)\n",
    "rf_y_test_pred = rf_clf.predict(X_test)\n",
    "rf_y_val_pred = rf_clf.predict(X_val)\n",
    "rf_test_acc = accuracy_score(y_test, rf_y_test_pred)\n",
    "rf_val_acc = accuracy_score(y_val, rf_y_val_pred)\n",
    "time.sleep(1)\n",
    "#Gradient Boosting\n",
    "gb_clf = GradientBoostingClassifier(n_estimators=100, random_state=0)\n",
    "gb_clf.fit(X_train, y_train)\n",
    "gb_y_test_pred = gb_clf.predict(X_test)\n",
    "gb_y_val_pred = gb_clf.predict(X_val)\n",
    "gb_test_acc = accuracy_score(y_test, gb_y_test_pred)\n",
    "gb_val_acc = accuracy_score(y_val, gb_y_val_pred)\n",
    "time.sleep(1)\n",
    "#Support Vector Machine\n",
    "svm_clf = SVC(kernel='linear')\n",
    "svm_clf.fit(X_train, y_train)\n",
    "svm_y_test_pred = svm_clf.predict(X_test)\n",
    "svm_y_val_pred = svm_clf.predict(X_val)\n",
    "svm_test_acc = accuracy_score(y_test, svm_y_test_pred)\n",
    "svm_val_acc = accuracy_score(y_val, svm_y_val_pred)\n",
    "time.sleep(1)\n",
    "print ('Result B1. 1-gram + 2-gram ')\n",
    "print (rf_test_acc,rf_val_acc,gb_test_acc,gb_val_acc,svm_test_acc,svm_val_acc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B2. 1-gram + 3-gram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result B2. 1-gram + 3-gram \n",
      "0.8165137614678899 0.8090909090909091 0.8623853211009175 0.8363636363636363 0.8348623853211009 0.8363636363636363\n"
     ]
    }
   ],
   "source": [
    "#B2. 1-gram + 3-gram\n",
    "corpus = data['supMentions'] + data['supNouns']\n",
    "corpus = corpus.fillna(value='')\n",
    "cv = CountVectorizer(min_df=2,ngram_range=(1,3),max_features=20000)\n",
    "data_cv = cv.fit_transform(corpus)\n",
    "cv_dtm = pd.DataFrame(data_cv.toarray(), columns=cv.get_feature_names())\n",
    "cv_dtm.index = corpus.index\n",
    "y = data['target']\n",
    "X = cv_dtm\n",
    "train_ratio = 0.75\n",
    "val_ratio = 0.15\n",
    "test_ratio = 0.15\n",
    "X_train, X_test_val, y_train, y_test_val = train_test_split(X, y, test_size=1-train_ratio, stratify=y, random_state=1)\n",
    "X_test, X_val, y_test, y_val = train_test_split(X_test_val, y_test_val, test_size=test_ratio/(test_ratio+val_ratio), stratify=y_test_val, random_state=1)\n",
    "#Random Forest\n",
    "rf_clf = RandomForestClassifier(n_estimators=100, random_state=0, n_jobs=-1)\n",
    "rf_clf.fit(X_train, y_train)\n",
    "rf_y_test_pred = rf_clf.predict(X_test)\n",
    "rf_y_val_pred = rf_clf.predict(X_val)\n",
    "rf_test_acc = accuracy_score(y_test, rf_y_test_pred)\n",
    "rf_val_acc = accuracy_score(y_val, rf_y_val_pred)\n",
    "time.sleep(1)\n",
    "#Gradient Boosting\n",
    "gb_clf = GradientBoostingClassifier(n_estimators=100, random_state=0)\n",
    "gb_clf.fit(X_train, y_train)\n",
    "gb_y_test_pred = gb_clf.predict(X_test)\n",
    "gb_y_val_pred = gb_clf.predict(X_val)\n",
    "gb_test_acc = accuracy_score(y_test, gb_y_test_pred)\n",
    "gb_val_acc = accuracy_score(y_val, gb_y_val_pred)\n",
    "time.sleep(1)\n",
    "#Support Vector Machine\n",
    "svm_clf = SVC(kernel='linear')\n",
    "svm_clf.fit(X_train, y_train)\n",
    "svm_y_test_pred = svm_clf.predict(X_test)\n",
    "svm_y_val_pred = svm_clf.predict(X_val)\n",
    "svm_test_acc = accuracy_score(y_test, svm_y_test_pred)\n",
    "svm_val_acc = accuracy_score(y_val, svm_y_val_pred)\n",
    "time.sleep(1)\n",
    "print ('Result B2. 1-gram + 3-gram ')\n",
    "print (rf_test_acc,rf_val_acc,gb_test_acc,gb_val_acc,svm_test_acc,svm_val_acc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B3. 2-gram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result B3. 2-gram\n",
      "0.6330275229357798 0.6636363636363637 0.6055045871559633 0.6454545454545455 0.6605504587155964 0.6727272727272727\n"
     ]
    }
   ],
   "source": [
    "#B3. 2-gram\n",
    "corpus = data['supMentions'] + data['supNouns']\n",
    "corpus = corpus.fillna(value='')\n",
    "cv = CountVectorizer(min_df=2,ngram_range=(2,2),max_features=20000)\n",
    "data_cv = cv.fit_transform(corpus)\n",
    "cv_dtm = pd.DataFrame(data_cv.toarray(), columns=cv.get_feature_names())\n",
    "cv_dtm.index = corpus.index\n",
    "y = data['target']\n",
    "X = cv_dtm\n",
    "train_ratio = 0.75\n",
    "val_ratio = 0.15\n",
    "test_ratio = 0.15\n",
    "X_train, X_test_val, y_train, y_test_val = train_test_split(X, y, test_size=1-train_ratio, stratify=y, random_state=1)\n",
    "X_test, X_val, y_test, y_val = train_test_split(X_test_val, y_test_val, test_size=test_ratio/(test_ratio+val_ratio), stratify=y_test_val, random_state=1)\n",
    "#Random Forest\n",
    "rf_clf = RandomForestClassifier(n_estimators=100, random_state=0, n_jobs=-1)\n",
    "rf_clf.fit(X_train, y_train)\n",
    "rf_y_test_pred = rf_clf.predict(X_test)\n",
    "rf_y_val_pred = rf_clf.predict(X_val)\n",
    "rf_test_acc = accuracy_score(y_test, rf_y_test_pred)\n",
    "rf_val_acc = accuracy_score(y_val, rf_y_val_pred)\n",
    "time.sleep(1)\n",
    "#Gradient Boosting\n",
    "gb_clf = GradientBoostingClassifier(n_estimators=100, random_state=0)\n",
    "gb_clf.fit(X_train, y_train)\n",
    "gb_y_test_pred = gb_clf.predict(X_test)\n",
    "gb_y_val_pred = gb_clf.predict(X_val)\n",
    "gb_test_acc = accuracy_score(y_test, gb_y_test_pred)\n",
    "gb_val_acc = accuracy_score(y_val, gb_y_val_pred)\n",
    "time.sleep(1)\n",
    "#Support Vector Machine\n",
    "svm_clf = SVC(kernel='linear')\n",
    "svm_clf.fit(X_train, y_train)\n",
    "svm_y_test_pred = svm_clf.predict(X_test)\n",
    "svm_y_val_pred = svm_clf.predict(X_val)\n",
    "svm_test_acc = accuracy_score(y_test, svm_y_test_pred)\n",
    "svm_val_acc = accuracy_score(y_val, svm_y_val_pred)\n",
    "time.sleep(1)\n",
    "print ('Result B3. 2-gram')\n",
    "print (rf_test_acc,rf_val_acc,gb_test_acc,gb_val_acc,svm_test_acc,svm_val_acc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B4. 2-gram + 3-gram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result B4. 2-gram + 3-gram\n",
      "0.6330275229357798 0.6545454545454545 0.6055045871559633 0.6363636363636364 0.6605504587155964 0.6727272727272727\n"
     ]
    }
   ],
   "source": [
    "#B4. 2-gram + 3-gram\n",
    "corpus = data['supMentions'] + data['supNouns']\n",
    "corpus = corpus.fillna(value='')\n",
    "cv = CountVectorizer(min_df=2,ngram_range=(2,3),max_features=20000)\n",
    "data_cv = cv.fit_transform(corpus)\n",
    "cv_dtm = pd.DataFrame(data_cv.toarray(), columns=cv.get_feature_names())\n",
    "cv_dtm.index = corpus.index\n",
    "y = data['target']\n",
    "X = cv_dtm\n",
    "train_ratio = 0.75\n",
    "val_ratio = 0.15\n",
    "test_ratio = 0.15\n",
    "X_train, X_test_val, y_train, y_test_val = train_test_split(X, y, test_size=1-train_ratio, stratify=y, random_state=1)\n",
    "X_test, X_val, y_test, y_val = train_test_split(X_test_val, y_test_val, test_size=test_ratio/(test_ratio+val_ratio), stratify=y_test_val, random_state=1)\n",
    "#Random Forest\n",
    "rf_clf = RandomForestClassifier(n_estimators=100, random_state=0, n_jobs=-1)\n",
    "rf_clf.fit(X_train, y_train)\n",
    "rf_y_test_pred = rf_clf.predict(X_test)\n",
    "rf_y_val_pred = rf_clf.predict(X_val)\n",
    "rf_test_acc = accuracy_score(y_test, rf_y_test_pred)\n",
    "rf_val_acc = accuracy_score(y_val, rf_y_val_pred)\n",
    "time.sleep(1)\n",
    "#Gradient Boosting\n",
    "gb_clf = GradientBoostingClassifier(n_estimators=100, random_state=0)\n",
    "gb_clf.fit(X_train, y_train)\n",
    "gb_y_test_pred = gb_clf.predict(X_test)\n",
    "gb_y_val_pred = gb_clf.predict(X_val)\n",
    "gb_test_acc = accuracy_score(y_test, gb_y_test_pred)\n",
    "gb_val_acc = accuracy_score(y_val, gb_y_val_pred)\n",
    "time.sleep(1)\n",
    "#Support Vector Machine\n",
    "svm_clf = SVC(kernel='linear')\n",
    "svm_clf.fit(X_train, y_train)\n",
    "svm_y_test_pred = svm_clf.predict(X_test)\n",
    "svm_y_val_pred = svm_clf.predict(X_val)\n",
    "svm_test_acc = accuracy_score(y_test, svm_y_test_pred)\n",
    "svm_val_acc = accuracy_score(y_val, svm_y_val_pred)\n",
    "time.sleep(1)\n",
    "print ('Result B4. 2-gram + 3-gram')\n",
    "print (rf_test_acc,rf_val_acc,gb_test_acc,gb_val_acc,svm_test_acc,svm_val_acc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B5. 3-gram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result B5. 3-gram\n",
      "0.5596330275229358 0.5636363636363636 0.5412844036697247 0.4909090909090909 0.5596330275229358 0.5909090909090909\n"
     ]
    }
   ],
   "source": [
    "#B5. 3-gram\n",
    "corpus = data['supMentions'] + data['supNouns']\n",
    "corpus = corpus.fillna(value='')\n",
    "cv = CountVectorizer(min_df=2,ngram_range=(3,3),max_features=20000)\n",
    "data_cv = cv.fit_transform(corpus)\n",
    "cv_dtm = pd.DataFrame(data_cv.toarray(), columns=cv.get_feature_names())\n",
    "cv_dtm.index = corpus.index\n",
    "y = data['target']\n",
    "X = cv_dtm\n",
    "train_ratio = 0.75\n",
    "val_ratio = 0.15\n",
    "test_ratio = 0.15\n",
    "X_train, X_test_val, y_train, y_test_val = train_test_split(X, y, test_size=1-train_ratio, stratify=y, random_state=1)\n",
    "X_test, X_val, y_test, y_val = train_test_split(X_test_val, y_test_val, test_size=test_ratio/(test_ratio+val_ratio), stratify=y_test_val, random_state=1)\n",
    "#Random Forest\n",
    "rf_clf = RandomForestClassifier(n_estimators=100, random_state=0, n_jobs=-1)\n",
    "rf_clf.fit(X_train, y_train)\n",
    "rf_y_test_pred = rf_clf.predict(X_test)\n",
    "rf_y_val_pred = rf_clf.predict(X_val)\n",
    "rf_test_acc = accuracy_score(y_test, rf_y_test_pred)\n",
    "rf_val_acc = accuracy_score(y_val, rf_y_val_pred)\n",
    "time.sleep(1)\n",
    "#Gradient Boosting\n",
    "gb_clf = GradientBoostingClassifier(n_estimators=100, random_state=0)\n",
    "gb_clf.fit(X_train, y_train)\n",
    "gb_y_test_pred = gb_clf.predict(X_test)\n",
    "gb_y_val_pred = gb_clf.predict(X_val)\n",
    "gb_test_acc = accuracy_score(y_test, gb_y_test_pred)\n",
    "gb_val_acc = accuracy_score(y_val, gb_y_val_pred)\n",
    "time.sleep(1)\n",
    "#Support Vector Machine\n",
    "svm_clf = SVC(kernel='linear')\n",
    "svm_clf.fit(X_train, y_train)\n",
    "svm_y_test_pred = svm_clf.predict(X_test)\n",
    "svm_y_val_pred = svm_clf.predict(X_val)\n",
    "svm_test_acc = accuracy_score(y_test, svm_y_test_pred)\n",
    "svm_val_acc = accuracy_score(y_val, svm_y_val_pred)\n",
    "time.sleep(1)\n",
    "print ('Result B5. 3-gram')\n",
    "print (rf_test_acc,rf_val_acc,gb_test_acc,gb_val_acc,svm_test_acc,svm_val_acc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### C1. TFIDF vectorizer (count sort)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result C1. TFIDF vectorizer (count sort)\n",
      "0.8256880733944955 0.8272727272727273 0.8532110091743119 0.8272727272727273 0.6330275229357798 0.6090909090909091 0.8623853211009175 0.8454545454545455 0.8256880733944955 0.7909090909090909 0.8532110091743119 0.7545454545454545\n"
     ]
    }
   ],
   "source": [
    "#C1. TFIDF vectorizer (count sort)\n",
    "corpus = data['supMentions'] + data['supNouns']\n",
    "corpus = corpus.fillna(value='')\n",
    "cv = TfidfVectorizer(min_df=2,ngram_range=(1,1),max_features=20000)\n",
    "data_cv = cv.fit_transform(corpus)\n",
    "cv_dtm = pd.DataFrame(data_cv.toarray(), columns=cv.get_feature_names())\n",
    "cv_dtm.index = corpus.index\n",
    "y = data['target']\n",
    "X = cv_dtm\n",
    "train_ratio = 0.75\n",
    "val_ratio = 0.15\n",
    "test_ratio = 0.15\n",
    "X_train, X_test_val, y_train, y_test_val = train_test_split(X, y, test_size=1-train_ratio, stratify=y, random_state=1)\n",
    "X_test, X_val, y_test, y_val = train_test_split(X_test_val, y_test_val, test_size=test_ratio/(test_ratio+val_ratio), stratify=y_test_val, random_state=1)\n",
    "#Random Forest\n",
    "rf_clf = RandomForestClassifier(n_estimators=100, random_state=0, n_jobs=-1)\n",
    "rf_clf.fit(X_train, y_train)\n",
    "rf_y_test_pred = rf_clf.predict(X_test)\n",
    "rf_y_val_pred = rf_clf.predict(X_val)\n",
    "rf_test_acc = accuracy_score(y_test, rf_y_test_pred)\n",
    "rf_val_acc = accuracy_score(y_val, rf_y_val_pred)\n",
    "time.sleep(1)\n",
    "#Gradient Boosting\n",
    "gb_clf = GradientBoostingClassifier(n_estimators=100, random_state=0)\n",
    "gb_clf.fit(X_train, y_train)\n",
    "gb_y_test_pred = gb_clf.predict(X_test)\n",
    "gb_y_val_pred = gb_clf.predict(X_val)\n",
    "gb_test_acc = accuracy_score(y_test, gb_y_test_pred)\n",
    "gb_val_acc = accuracy_score(y_val, gb_y_val_pred)\n",
    "time.sleep(1)\n",
    "#Support Vector Machine\n",
    "svm_clf = SVC(kernel='linear')\n",
    "svm_clf.fit(X_train, y_train)\n",
    "svm_y_test_pred = svm_clf.predict(X_test)\n",
    "svm_y_val_pred = svm_clf.predict(X_val)\n",
    "svm_test_acc = accuracy_score(y_test, svm_y_test_pred)\n",
    "svm_val_acc = accuracy_score(y_val, svm_y_val_pred)\n",
    "time.sleep(1)\n",
    "print ('Result C1. TFIDF vectorizer (count sort)')\n",
    "print (rf_test_acc,rf_val_acc,gb_test_acc,gb_val_acc,svm_test_acc,svm_val_acc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### C2. TFIDF vectorizer (arg sort)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result C2. TFIDF vectorizer (arg sort)\n",
      "0.8256880733944955 0.8272727272727273 0.8532110091743119 0.8272727272727273 0.8623853211009175 0.8454545454545455\n"
     ]
    }
   ],
   "source": [
    "#C2. TFIDF vectorizer (arg sort)\n",
    "corpus = data['supMentions'] + data['supNouns']\n",
    "corpus = corpus.fillna(value='')\n",
    "cv = TfidfVectorizer(min_df=2,ngram_range=(1,1)) #no max_features used\n",
    "data_cv = cv.fit_transform(corpus)\n",
    "\n",
    "# use agrsort() instead of the built-in max_features functionality\n",
    "arg_sorted = np.argsort(cv.idf_)[::-1] # This sorts all the array elements in the 2 dimensional matrix\n",
    "features = cv.get_feature_names()\n",
    "top_features = [features[i] for i in arg_sorted[:20000]] #get top 20000 features\n",
    "\n",
    "cv_dtm = pd.DataFrame(data_cv.toarray(), columns=top_features)\n",
    "cv_dtm.index = corpus.index\n",
    "y = data['target']\n",
    "X = cv_dtm\n",
    "train_ratio = 0.75\n",
    "val_ratio = 0.15\n",
    "test_ratio = 0.15\n",
    "X_train, X_test_val, y_train, y_test_val = train_test_split(X, y, test_size=1-train_ratio, stratify=y, random_state=1)\n",
    "X_test, X_val, y_test, y_val = train_test_split(X_test_val, y_test_val, test_size=test_ratio/(test_ratio+val_ratio), stratify=y_test_val, random_state=1)\n",
    "#Random Forest\n",
    "rf_clf = RandomForestClassifier(n_estimators=100, random_state=0, n_jobs=-1)\n",
    "rf_clf.fit(X_train, y_train)\n",
    "rf_y_test_pred = rf_clf.predict(X_test)\n",
    "rf_y_val_pred = rf_clf.predict(X_val)\n",
    "rf_test_acc = accuracy_score(y_test, rf_y_test_pred)\n",
    "rf_val_acc = accuracy_score(y_val, rf_y_val_pred)\n",
    "time.sleep(1)\n",
    "#Gradient Boosting\n",
    "gb_clf = GradientBoostingClassifier(n_estimators=100, random_state=0)\n",
    "gb_clf.fit(X_train, y_train)\n",
    "gb_y_test_pred = gb_clf.predict(X_test)\n",
    "gb_y_val_pred = gb_clf.predict(X_val)\n",
    "gb_test_acc = accuracy_score(y_test, gb_y_test_pred)\n",
    "gb_val_acc = accuracy_score(y_val, gb_y_val_pred)\n",
    "time.sleep(1)\n",
    "#Support Vector Machine\n",
    "svm_clf = SVC(kernel='linear')\n",
    "svm_clf.fit(X_train, y_train)\n",
    "svm_y_test_pred = svm_clf.predict(X_test)\n",
    "svm_y_val_pred = svm_clf.predict(X_val)\n",
    "svm_test_acc = accuracy_score(y_test, svm_y_test_pred)\n",
    "svm_val_acc = accuracy_score(y_val, svm_y_val_pred)\n",
    "time.sleep(1)\n",
    "print ('Result C2. TFIDF vectorizer (arg sort)')\n",
    "print (rf_test_acc,rf_val_acc,gb_test_acc,gb_val_acc,svm_test_acc,svm_val_acc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### D1. 10k Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result D1. 10k Features\n",
      "0.8440366972477065 0.8181818181818182 0.8532110091743119 0.8181818181818182 0.8623853211009175 0.8363636363636363\n"
     ]
    }
   ],
   "source": [
    "#D1. 10k Features\n",
    "corpus = data['supMentions'] + data['supNouns']\n",
    "corpus = corpus.fillna(value='')\n",
    "cv = CountVectorizer(min_df=2,ngram_range=(1,1),max_features=10000)\n",
    "data_cv = cv.fit_transform(corpus)\n",
    "cv_dtm = pd.DataFrame(data_cv.toarray(), columns=cv.get_feature_names())\n",
    "cv_dtm.index = corpus.index\n",
    "y = data['target']\n",
    "X = cv_dtm\n",
    "train_ratio = 0.75\n",
    "val_ratio = 0.15\n",
    "test_ratio = 0.15\n",
    "X_train, X_test_val, y_train, y_test_val = train_test_split(X, y, test_size=1-train_ratio, stratify=y, random_state=1)\n",
    "X_test, X_val, y_test, y_val = train_test_split(X_test_val, y_test_val, test_size=test_ratio/(test_ratio+val_ratio), stratify=y_test_val, random_state=1)\n",
    "#Random Forest\n",
    "rf_clf = RandomForestClassifier(n_estimators=100, random_state=0, n_jobs=-1)\n",
    "rf_clf.fit(X_train, y_train)\n",
    "rf_y_test_pred = rf_clf.predict(X_test)\n",
    "rf_y_val_pred = rf_clf.predict(X_val)\n",
    "rf_test_acc = accuracy_score(y_test, rf_y_test_pred)\n",
    "rf_val_acc = accuracy_score(y_val, rf_y_val_pred)\n",
    "time.sleep(1)\n",
    "#Gradient Boosting\n",
    "gb_clf = GradientBoostingClassifier(n_estimators=100, random_state=0)\n",
    "gb_clf.fit(X_train, y_train)\n",
    "gb_y_test_pred = gb_clf.predict(X_test)\n",
    "gb_y_val_pred = gb_clf.predict(X_val)\n",
    "gb_test_acc = accuracy_score(y_test, gb_y_test_pred)\n",
    "gb_val_acc = accuracy_score(y_val, gb_y_val_pred)\n",
    "time.sleep(1)\n",
    "#Support Vector Machine\n",
    "svm_clf = SVC(kernel='linear')\n",
    "svm_clf.fit(X_train, y_train)\n",
    "svm_y_test_pred = svm_clf.predict(X_test)\n",
    "svm_y_val_pred = svm_clf.predict(X_val)\n",
    "svm_test_acc = accuracy_score(y_test, svm_y_test_pred)\n",
    "svm_val_acc = accuracy_score(y_val, svm_y_val_pred)\n",
    "time.sleep(1)\n",
    "print ('Result D1. 10k Features')\n",
    "print (rf_test_acc,rf_val_acc,gb_test_acc,gb_val_acc,svm_test_acc,svm_val_acc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### D2. 5k Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result D1. 5k Features\n",
      "0.8256880733944955 0.8181818181818182 0.8440366972477065 0.8272727272727273 0.8440366972477065 0.8545454545454545\n"
     ]
    }
   ],
   "source": [
    "#D2. 5k Features\n",
    "corpus = data['supMentions'] + data['supNouns']\n",
    "corpus = corpus.fillna(value='')\n",
    "cv = CountVectorizer(min_df=2,ngram_range=(1,1),max_features=5000)\n",
    "data_cv = cv.fit_transform(corpus)\n",
    "cv_dtm = pd.DataFrame(data_cv.toarray(), columns=cv.get_feature_names())\n",
    "cv_dtm.index = corpus.index\n",
    "y = data['target']\n",
    "X = cv_dtm\n",
    "train_ratio = 0.75\n",
    "val_ratio = 0.15\n",
    "test_ratio = 0.15\n",
    "X_train, X_test_val, y_train, y_test_val = train_test_split(X, y, test_size=1-train_ratio, stratify=y, random_state=1)\n",
    "X_test, X_val, y_test, y_val = train_test_split(X_test_val, y_test_val, test_size=test_ratio/(test_ratio+val_ratio), stratify=y_test_val, random_state=1)\n",
    "#Random Forest\n",
    "rf_clf = RandomForestClassifier(n_estimators=100, random_state=0, n_jobs=-1)\n",
    "rf_clf.fit(X_train, y_train)\n",
    "rf_y_test_pred = rf_clf.predict(X_test)\n",
    "rf_y_val_pred = rf_clf.predict(X_val)\n",
    "rf_test_acc = accuracy_score(y_test, rf_y_test_pred)\n",
    "rf_val_acc = accuracy_score(y_val, rf_y_val_pred)\n",
    "time.sleep(1)\n",
    "#Gradient Boosting\n",
    "gb_clf = GradientBoostingClassifier(n_estimators=100, random_state=0)\n",
    "gb_clf.fit(X_train, y_train)\n",
    "gb_y_test_pred = gb_clf.predict(X_test)\n",
    "gb_y_val_pred = gb_clf.predict(X_val)\n",
    "gb_test_acc = accuracy_score(y_test, gb_y_test_pred)\n",
    "gb_val_acc = accuracy_score(y_val, gb_y_val_pred)\n",
    "time.sleep(1)\n",
    "#Support Vector Machine\n",
    "svm_clf = SVC(kernel='linear')\n",
    "svm_clf.fit(X_train, y_train)\n",
    "svm_y_test_pred = svm_clf.predict(X_test)\n",
    "svm_y_val_pred = svm_clf.predict(X_val)\n",
    "svm_test_acc = accuracy_score(y_test, svm_y_test_pred)\n",
    "svm_val_acc = accuracy_score(y_val, svm_y_val_pred)\n",
    "time.sleep(1)\n",
    "print ('Result D2. 5k Features')\n",
    "print (rf_test_acc,rf_val_acc,gb_test_acc,gb_val_acc,svm_test_acc,svm_val_acc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### E1. Execution Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result E1. Execution Time\n",
      "1.611 142.4 3.219\n"
     ]
    }
   ],
   "source": [
    "#E1. Execution Time\n",
    "def getTiming(timingText):\n",
    "    m = re.search('Duration: ', timingText)\n",
    "    return (timingText[m.end(): m.end()+5])\n",
    "\n",
    "timing = Profiler() # from the pyInstrument library\n",
    "\n",
    "corpus = data['supMentions'] + data['supNouns']\n",
    "corpus = corpus.fillna(value='')\n",
    "cv = CountVectorizer(min_df=2,ngram_range=(1,1),max_features=20000)\n",
    "data_cv = cv.fit_transform(corpus)\n",
    "cv_dtm = pd.DataFrame(data_cv.toarray(), columns=cv.get_feature_names())\n",
    "cv_dtm.index = corpus.index\n",
    "y = data['target']\n",
    "X = cv_dtm\n",
    "train_ratio = 0.75\n",
    "val_ratio = 0.15\n",
    "test_ratio = 0.15\n",
    "X_train, X_test_val, y_train, y_test_val = train_test_split(X, y, test_size=1-train_ratio, stratify=y, random_state=1)\n",
    "X_test, X_val, y_test, y_val = train_test_split(X_test_val, y_test_val, test_size=test_ratio/(test_ratio+val_ratio), stratify=y_test_val, random_state=1)\n",
    "#Random Forest\n",
    "timing.start()\n",
    "rf_clf = RandomForestClassifier(n_estimators=100, random_state=0, n_jobs=-1)\n",
    "rf_clf.fit(X_train, y_train)\n",
    "rf_y_test_pred = rf_clf.predict(X_test)\n",
    "rf_y_val_pred = rf_clf.predict(X_val)\n",
    "rf_test_acc = accuracy_score(y_test, rf_y_test_pred)\n",
    "rf_val_acc = accuracy_score(y_val, rf_y_val_pred)\n",
    "timing.stop()\n",
    "rf_exe_time = getTiming(timing.output_text())\n",
    "time.sleep(1)\n",
    "#Gradient Boosting\n",
    "timing.start()\n",
    "gb_clf = GradientBoostingClassifier(n_estimators=100, random_state=0)\n",
    "gb_clf.fit(X_train, y_train)\n",
    "gb_y_test_pred = gb_clf.predict(X_test)\n",
    "gb_y_val_pred = gb_clf.predict(X_val)\n",
    "gb_test_acc = accuracy_score(y_test, gb_y_test_pred)\n",
    "gb_val_acc = accuracy_score(y_val, gb_y_val_pred)\n",
    "timing.stop()\n",
    "gb_exe_time = getTiming(timing.output_text())\n",
    "time.sleep(1)\n",
    "#Support Vector Machine\n",
    "timing.start()\n",
    "svm_clf = SVC(kernel='linear')\n",
    "svm_clf.fit(X_train, y_train)\n",
    "svm_y_test_pred = svm_clf.predict(X_test)\n",
    "svm_y_val_pred = svm_clf.predict(X_val)\n",
    "svm_test_acc = accuracy_score(y_test, svm_y_test_pred)\n",
    "svm_val_acc = accuracy_score(y_val, svm_y_val_pred)\n",
    "timing.stop()\n",
    "svm_exe_time = getTiming(timing.output_text())\n",
    "time.sleep(1)\n",
    "print ('Result E1. Execution Time')\n",
    "print (rf_exe_time,gb_exe_time,svm_exe_time)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
